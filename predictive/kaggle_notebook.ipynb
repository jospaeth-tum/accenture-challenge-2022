{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"datathon_SC_ACN_22/\"\n",
    "SEP = \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114276, 9) (666, 5) (6660, 8) (772, 3) (772, 2) (28563, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ports that are the same but have different names (data cleaning)\n",
    "same_ports =  {\n",
    "    'ATHENAS': 'Athens',\n",
    "    'BCN': 'Barcelona',\n",
    "}\n",
    "\n",
    "# converters function for pd.read_csv()\n",
    "convs = {\n",
    "    'origin_port': lambda x: same_ports[x] if x in same_ports else x\n",
    "}\n",
    "\n",
    "df_cities = pd.read_csv(DATA_FOLDER + \"cities_data.csv\", sep=SEP)\n",
    "df_cities_costs = pd.read_csv(DATA_FOLDER + \"cities_data_costs.csv\", sep=\",\")\n",
    "df_orders = pd.read_csv(\n",
    "  DATA_FOLDER + \"orders.csv\",\n",
    "  sep=SEP,\n",
    "  na_filter=False,\n",
    "  converters=convs)\n",
    "df_product_attr = pd.read_csv(DATA_FOLDER + \"product_attributes.csv\", sep=\",\")\n",
    "df_product_weight_class = pd.read_csv(DATA_FOLDER + \"product_weight_class.csv\", sep=\",\")\n",
    "df_test = pd.read_csv(\n",
    "  DATA_FOLDER + \"test.csv\",\n",
    "  sep=SEP,\n",
    "  na_filter=False,\n",
    "  converters=convs)\n",
    "print(df_orders.shape, df_cities.shape, df_cities_costs.shape, df_product_attr.shape, df_product_weight_class.shape, df_test.shape)\n",
    "\n",
    "# # the inner merge operation would get rid of 118 orders that have product_id -1\n",
    "# df_orders = df_orders.merge(df_product_attr, on=\"product_id\", how=\"left\")\n",
    "\n",
    "# # fill NaN values\n",
    "# df_orders[\"material_handling\"] = df_orders[\"material_handling\"].fillna(-1)\n",
    "# # use mean of weights for missing weights\n",
    "# mean_weight = df_orders[\"weight\"].mean()\n",
    "# df_orders[\"weight\"] = df_orders[\"weight\"].fillna(mean_weight)\n",
    "# print(df_orders.shape)\n",
    "# print(df_orders[df_orders[\"product_id\"] == -1])\n",
    "\n",
    "# sort values, which will help later with creating the datasets for ML\n",
    "df_orders.sort_values(\"late_order\", inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: (114276, 819)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "one_hot_raw_features = df_orders.drop(\n",
    "  columns=[\"order_id\", \"late_order\", \"units\"])#, \"weight\", \"material_handling\"])\n",
    "enc.fit(one_hot_raw_features)\n",
    "# print(enc.categories_)\n",
    "one_hot_features = np.array(enc.transform(one_hot_raw_features).toarray())\n",
    "\n",
    "# scale the unit values\n",
    "unscaled_units = df_orders[\"units\"].to_numpy()[:, np.newaxis]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(unscaled_units)\n",
    "units_scaled = scaler.transform(unscaled_units)\n",
    "# print(units_scaled)\n",
    "\n",
    "raw_X = np.concatenate([one_hot_features, units_scaled], axis=1) \n",
    "raw_y = df_orders[\"late_order\"]\n",
    "# print(raw_X)\n",
    "print(\"Feature size:\", raw_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114276 total\n",
      "{'0': 87120, '1': 27156} -> 0.7623648010080857 negative\n",
      "X: (108624, 819) y: (108624,)\n",
      "ratio: 0.5\n",
      "split at 76036\n"
     ]
    }
   ],
   "source": [
    "### Balance out features and targets\n",
    "\n",
    "# count amount of negatives\n",
    "num_positives = sum(raw_y)\n",
    "num_negatives = len(raw_y) - num_positives\n",
    "\n",
    "assert sum(raw_y[:num_negatives]) == 0\n",
    "assert sum(raw_y[num_negatives:]) == num_positives\n",
    "\n",
    "print(len(raw_y), \"total\")\n",
    "print({\n",
    "  \"0\": num_negatives,\n",
    "  \"1\": num_positives\n",
    "}, \"->\", num_negatives / len(raw_y), \"negative\")\n",
    "\n",
    "# select negative features\n",
    "perm = np.random.permutation(num_negatives)\n",
    "negative_X = raw_X[perm[:num_positives*2]]\n",
    "negative_y = raw_y[perm[:num_positives*2]]\n",
    "\n",
    "# select positive features\n",
    "positive_X = raw_X[num_negatives:]\n",
    "positive_y = raw_y[num_negatives:]\n",
    "\n",
    "# concatenate features\n",
    "X = np.concatenate((negative_X, positive_X, positive_X), axis=0)\n",
    "y = np.concatenate((negative_y, positive_y, positive_y), axis=0)\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)\n",
    "print(\"ratio:\", sum(y) / len(y))\n",
    "\n",
    "# shuffle datasets\n",
    "shuffle_perm = np.random.permutation(len(X))\n",
    "X = X[shuffle_perm]\n",
    "y = y[shuffle_perm]\n",
    "\n",
    "split = (len(y) * 7) // 10\n",
    "print(\"split at\", split)\n",
    "X_train, y_train = X[:split], y[:split]\n",
    "X_test, y_test = X[split:], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train models\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# svm_model = SVC(gamma=\"auto\")\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "# TODO: adjust data for tree and output tree\n",
    "# X_train_tree = np.concatenate([\n",
    "#   enc.inverse_transform(X_train[:, :-1]),\n",
    "#   X_train[:, -1:]], axis=1)\n",
    "\n",
    "# X_test_tree = np.concatenate([\n",
    "#   enc.inverse_transform(X_test[:, :-1]),\n",
    "#   X_test[:, -1:]], axis=1)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "log_model = LogisticRegression(solver=\"sag\")\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred [ True False  True ... False  True  True]\n",
      "pred ratio 0.5686142138210384\n",
      "tree acc: 0.7975942064563643\n",
      "pred [False False False ... False  True False]\n",
      "pred ratio 0.48959739781514666\n",
      "log acc: 0.7470541303547318\n"
     ]
    }
   ],
   "source": [
    "# evaluate the approaches\n",
    "def eval_model(pred_fn, name):\n",
    "  pred = pred_fn(X_test)\n",
    "  print(\"pred\", pred)\n",
    "  print(\"pred ratio\", sum(pred) / len(X_test))\n",
    "  hits = sum([1 if y_hat == y else 0 for (y_hat, y) in zip(pred, y_test) ])\n",
    "  print(name, \"acc:\", hits / len(pred))\n",
    "\n",
    "# eval_model(svm_model.predict, \"svm\")\n",
    "\n",
    "eval_model(tree_model.predict, \"tree\")\n",
    "# simple: 0.80\n",
    "\n",
    "eval_model(log_model.predict, \"log\")\n",
    "# simple: 0.75\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: (28563, 819)\n",
      "[[0.79240504 0.20759496]\n",
      " [0.65479479 0.34520521]\n",
      " [0.50340932 0.49659068]\n",
      " ...\n",
      " [0.7311204  0.2688796 ]\n",
      " [0.21507062 0.78492938]\n",
      " [0.51989275 0.48010725]]\n"
     ]
    }
   ],
   "source": [
    "# make features with testing data\n",
    "one_hot_raw_features = df_test.drop(\n",
    "  columns=[\"order_id\", \"units\"])#, \"weight\", \"material_handling\"])\n",
    "one_hot_features = np.array(enc.transform(one_hot_raw_features).toarray())\n",
    "\n",
    "# scale the unit values\n",
    "unscaled_units = df_test[\"units\"].to_numpy()[:, np.newaxis]\n",
    "units_scaled = scaler.transform(unscaled_units)\n",
    "\n",
    "X_eval = np.concatenate([one_hot_features, units_scaled], axis=1) \n",
    "print(\"Feature size:\", X_eval.shape)\n",
    "\n",
    "# evaluate test cases\n",
    "probs = log_model.predict_proba(X_eval)\n",
    "print(probs)\n",
    "\n",
    "# print probabilities\n",
    "submission = pd.DataFrame({\"order_id\": df_test.order_id, \"late_order\": probs[:,1]})\n",
    "submission.to_csv(\"submission/submission_kaggle_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
